<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Brian B. Avants (PENN) and Nicholas J. Tustison (UVA)" />
  <title>Building a house withAdvanced Normalization Tools (ANTs)</title>
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <link rel="stylesheet" href="index_files/reveal.js-2.6.1/css/reveal.min.css"/>

  <!-- some tweaks to reveal css -->
  <style type="text/css">
    .reveal h1 { font-size: 2.0em; }
    .reveal h2 { font-size: 1.5em;  }
    .reveal h3 { font-size: 1.25em;	}
    .reveal h4 { font-size: 1em;	}

    .reveal .slides>section,
    .reveal .slides>section>section {
      padding: 0px 0px;
    }



    .reveal table {
      border-width: 1px;
      border-spacing: 2px;
      border-style: dotted;
      border-color: gray;
      border-collapse: collapse;
      font-size: 0.7em;
    }

    .reveal table th {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      font-weight: bold;
      border-style: dotted;
      border-color: gray;
    }

    .reveal table td {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      border-style: dotted;
      border-color: gray;
    }

  </style>

    <style type="text/css">code{white-space: pre;}</style>


<style type="text/css">
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #303030; color: #cccccc; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; }
td.sourceCode { padding-left: 5px; }
pre, code { color: #cccccc; background-color: #303030; }
code > span.kw { color: #f0dfaf; }
code > span.dt { color: #dfdfbf; }
code > span.dv { color: #dcdccc; }
code > span.bn { color: #dca3a3; }
code > span.fl { color: #c0bed1; }
code > span.ch { color: #dca3a3; }
code > span.st { color: #cc9393; }
code > span.co { color: #7f9f7f; }
code > span.ot { color: #efef8f; }
code > span.al { color: #ffcfaf; }
code > span.fu { color: #efef8f; }
code > span.er { color: #c3bf9f; }
</style>

<link rel="stylesheet" href="index_files/reveal.js-2.6.1/css/theme/night.css" id="theme">

<style type="text/css">
.reveal section img {
  background: rgba(255, 255, 255, 0.85);
}
</style>

    <!-- If the query includes 'print-pdf', include the PDF print sheet -->
    <script>
      if( window.location.search.match( /print-pdf/gi ) ) {
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = 'index_files/reveal.js-2.6.1/css/print/pdf.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
      }
    </script>
    <!--[if lt IE 9]>
    <script src="index_files/reveal.js-2.6.1/lib/js/html5shiv.js"></script>
    <![endif]-->

</head>
<body>
  <div class="reveal">
    <div class="slides">

<section>
    <h1 class="title"><span style="color:red;">Building a house with<br />Advanced Normalization Tools (<em>ANTs</em>)</span></h1>
    <h2 class="author">Brian B. Avants (<span style="color:blue;">PENN</span>) and <br />Nicholas J. Tustison (<span style="color:orange;">UVA</span>)</h2>
    <h3 class="date"></h3>
</section>

<section id="section" class="slide level2">
<h1></h1>
<div align="center">
<img src="figures/brian_and_edie_sedgwick.jpg" frameborder="0"></img>
</div>
<p>This talk is online at <a href="http://stnava.github.io/ANTs2015/"><a href="http://stnava.github.io/ANTs2015/" class="uri">http://stnava.github.io/ANTs2015/</a></a> with colored <a href="http://stnava.github.io/ANTs2015/">links</a> meant to be clicked for more information.</p>
</section>
<section><section id="background" class="titleslide slide level1"><h1>Background</h1></section><section id="founding-developers" class="slide level2">
<h1>Founding developers</h1>
<div align="center">
<img width="1800" src="./figures/bant2.png" frameborder="0"></img>
</div>
<p>BBA &amp; NT</p>
</section><section id="long-term-collaborators" class="slide level2">
<h1>Long-term collaborators</h1>
<p><img src="figures/antscollab.jpg" /></p>
<p><span class="math">\(+\)</span> <a href="http://neuro.debian.net/pkgs/ants.html">neurodebian</a>, <a href="http://www.slicer.org/">slicer</a>, <a href="https://github.com/BRAINSia/BRAINSTools">brainsfit</a>, <a href="http://nipy.sourceforge.net/nipype/">nipype</a>, <a href="http://www.itk.org">itk</a> and more …</p>
</section><section id="section-1" class="slide level2">
<h1></h1>
<p><img src="figures/lion.png" /></p>
<p>a pride: common way of doing things</p>
<p>… in a competitive world …</p>
</section><section id="definitions" class="slide level2">
<h1>Definitions</h1>
<ul>
<li class="fragment"><p>Registration <span class="math">\(=\)</span> estimate an “optimal” geometric mapping between image pairs or image sets (e.g. Affine)</p></li>
<li class="fragment"><p><span style="color:grey;"> Similarity <span class="math">\(=\)</span> a function relating one image to another, given a transformation (e.g. mutual information)</span></p></li>
<li class="fragment"><p>Diffeomorphisms <span class="math">\(=\)</span> differentiable map with differentiable inverse (e.g. “silly putty”, viscous fluid)</p></li>
<li class="fragment"><p><span style="color:grey;">Segmentation <span class="math">\(=\)</span> labeling tissue or anatomy in images, usually automated (e.g. K-means)</span></p></li>
<li class="fragment"><p>Multivariate <span class="math">\(=\)</span> using many voxels or measurements at once (e.g. PCA, <span class="math">\(p &gt;&gt; n\)</span> ridge regression)</span></p></li>
<li class="fragment"><p><span style="color:grey;">Multiple modality <span class="math">\(=\)</span> using many modalities at once (e.g. DTI and T1 and BOLD)</span></p></li>
<li class="fragment"><p>MALF: multi-atlas label fusion - using anatomical dictionaries to label new data</p></li>
<li class="fragment"><p><span style="color:grey;">Solutions to challenging statistical image processing problems usually need elements from each of the above</span></p></li>
</ul>
</section><section id="image-mapping-perception-1878" class="slide level2">
<h1>Image mapping &amp; perception: 1878</h1>
<p><img src="figures/galton.png" /></p>
<ul>
<li class="fragment"><p>Francis Galton: Can we see criminality in the face?</p></li>
<li class="fragment"><p>(maybe he should have used ANTs?)</p></li>
</ul>
</section><section id="image-mapping-biology-1917" class="slide level2">
<h1>Image mapping &amp; biology: 1917</h1>
<p><img src="figures/dthompson.png" /></p>
</section><section id="initial-scope" class="slide level2">
<h1>Initial scope</h1>
<p><img src="figures/ants_initial_scope.png" /></p>
<p>… just do a better registration (tell story) …</p>
</section><section id="ants-lineage" class="slide level2">
<h1>ANTs Lineage</h1>
<p><img src="figures/lineage.jpg" /></p>
<p>References: <span class="citation" data-cites="Horn1981">Horn and Schunck (1981)</span>, <span class="citation" data-cites="Gee1993">Gee, Reivich, and Bajcsy (1993)</span>, <span class="citation" data-cites="Grenander1993">Grenander (1993)</span>, <span class="citation" data-cites="Thompson2001">Thompson et al. (2001)</span>, <span class="citation" data-cites="Miller2002">Miller, Trouve, and Younes (2002)</span>, <span class="citation" data-cites="Shen2002">Shen and Davatzikos (2002)</span>, <span class="citation" data-cites="Arnold2014">Arnold (2014)</span>, <span class="citation" data-cites="Thirion1998">Thirion (1998)</span>, <span class="citation" data-cites="Rueckert1999">Rueckert et al. (1999)</span>, <span class="citation" data-cites="Fischl2012">Fischl (2012)</span>, <span class="citation" data-cites="Ashburner2012">Ashburner (2012)</span></p>
</section><section id="diffeomorphisms" class="slide level2">
<h1>Diffeomorphisms</h1>
<div align="center">
<img width="1433" src="./figures/sillyputty.png" frameborder="0"></img>
</div>
<p>plausible physical modeling of large, invertible deformations</p>
<p>“differentiable map with differentiable inverse”</p>
</section><section id="fine-grained-and-flexible-maps" class="slide level2">
<h1>Fine-grained and flexible maps</h1>
<p><img src="figures/highresdiffeos.jpg" /></p>
<p>… to correct a misconception about diffeomorphisms …</p>
</section><section id="diffeomorphisms-image-parameterization-in-a-metric-space" class="slide level2">
<h1>Diffeomorphisms: image parameterization in a metric space</h1>
<p><img src="figures/shape_appearance.png" /></p>
</section><section id="general-purpose-library-for-multivariate-image-registration-segmentation-statistical-analysis-tools" class="slide level2">
<h1>General purpose library for multivariate image registration, segmentation &amp; statistical analysis tools</h1>
<ul>
<li class="fragment"><p>170,000+ lines of C++, 6<span class="math">\(+\)</span> years of work, 15+ collaborators.</p></li>
<li class="fragment"><p>Generic mathematical methods that are tunable for application specific domains: no-free lunch</p></li>
<li class="fragment"><p>Deep testing on multiple platforms … osx, linux, windows.</p></li>
<li class="fragment"><p>Several “wins” in public knock-abouts ( <a href="http://www.ncbi.nlm.nih.gov/pubmed/19195496">Klein 2009</a>, <a href="http://www.ncbi.nlm.nih.gov/pubmed/21632295">Murphy 2011</a>, <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3837555/">SATA 2012 and 2013</a>, <a href="http://martinos.org/qtim/miccai2013/proc_brats_2013.pdf">BRATS 2013</a>, others )</p></li>
</ul>
<pre><code>    An algorithm must use prior knowledge about a problem 
    to do well on that problem </code></pre>
</section><section id="ants-beyond-registration" class="slide level2">
<h1>ANTs: Beyond Registration</h1>
<p><img src="figures/antscapabilities.jpg" /></p>
<p><a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=atropos+tustison">Atropos</a> segmentation, <a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=N4+tustison">N4 inhomogeneity correction</a>, <a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=eigenanatomy+avants">Eigenanatomy</a>, <a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=sparse+canonical+avants">SCCAN</a>, <a href="http://www.ncbi.nlm.nih.gov/pubmed/24852460">Prior-constrained PCA</a>, and <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4009425/">atlas-based label fusion</a> and <a href="http://www.ncbi.nlm.nih.gov/pubmed/21237273">MALF</a> (powerful expert systems for segmentation)</p>
<p>```</p>
</section><section id="on-documentation" class="slide level2">
<h1>On documentation</h1>
<p><img src="figures/handsaw.jpg" /></p>
<p>simple and nearly self-explanatory</p>
</section><section id="on-documentation-1" class="slide level2">
<h1>On documentation</h1>
<p><img src="figures/Chainsaw.jpg" /></p>
<p>documentation is important</p>
</section><section id="on-documentation-2" class="slide level2">
<h1>On documentation</h1>
<p><img src="figures/blindmen.jpg" /></p>
<p>… developers can be blind to doc deficiencies</p>
<p>while users are blind to what we provide!</p>
</section></section>
<section><section id="ants-impact" class="titleslide slide level1"><h1>ANTs Impact</h1></section><section id="ants-statistics" class="slide level2">
<h1>ANTs Statistics</h1>
<p><img src="impact/figures/antsvisitors.png" /></p>
</section><section id="ants-neuroscience" class="slide level2">
<h1>ANTs &amp; Neuroscience</h1>
<p>We need statistical image analysis <br />at several scales in modern neuroscience</p>
<ul>
<li class="fragment"><p>Macro: <em>in vivo</em> structural and functional MRI</p></li>
<li class="fragment"><p>Micro: high-resolution post-mortem MRI links with in vivo MRI</p></li>
<li class="fragment"><p>Nano: neuron reconstruction …</p></li>
<li class="fragment"><p>Solutions that are consistent across these scales have the potential to build multi-scale feature sets or templates and provide new insights into brain structure and function</p></li>
<li class="fragment"><p>E.g. Parcellation constraints based on histology, tractography, function …</p></li>
<li class="fragment"><p>Statistical definitions of anatomy/pathology?</p></li>
<li class="fragment"><p>Reinvention of these solutions within each lab … can we mitigate this?</p></li>
<li class="fragment"><p>Reduce, reuse, recycle …</p></li>
</ul>
</section><section id="financial-impact" class="slide level2">
<h1>Financial impact</h1>
<ul>
<li class="fragment"><p>The <strong>high error rate</strong> in software makes testing for quality assurance critically important.</p></li>
<li class="fragment"><p>Bugs exist <strong>Everywhere</strong>: so don’t freak out if we admit we have bugs: we’re just being honest ( and not all devs are )</p></li>
<li class="fragment"><p>Virtually every business in the United States now depends on software for development, production, distribution, and after-sales support of products and services.</p></li>
<li class="fragment"><p>A 2002 NIST study estimated the direct costs to the software supply chain due to failure to identify (<strong>successfully test for</strong>) “bugs”</p></li>
<li class="fragment"><p>We are better at this than most … <strong>not perfect</strong></p></li>
<li class="fragment"><p>The estimate of direct costs compiled from industry survey data for the U.S. economy was <strong>$60 billion per year</strong></p></li>
<li class="fragment"><p>… this estimate did not include costs to end users such as lost business (for example, the cost of shutting down the New York Mercantile Exchange in 1998 due to a software failure).</p></li>
</ul>
</section><section id="reproducibility" class="slide level2">
<h1>Reproducibility</h1>
<ul>
<li class="fragment"><p>Consider the recent paper: <a href="http://ac.els-cdn.com/S2213158214001260/1-s2.0-S2213158214001260-main.pdf?_tid=8e6f5248-335d-11e4-ba4f-00000aab0f02&amp;acdnat=1409743944_6615d59eb5709e6bcb1aca76450f7d93">Freesurfer, laplacian, DiReCT thickness in longitudinal stroke</a></p></li>
<li class="fragment"><p>We “pre-wrote” a comment: <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3766821/?report=reader">Instrumentation bias in the use and evaluation of scientific software</a></p></li>
<li class="fragment"><p>With these guys:</p></li>
<li class="fragment"><p><img src="figures/luis.jpg" style="height: 256px; float: middle; margin-bottom: 15px; margin-right: 3px;"><img src="figures/torsten.jpg" style="height: 256px; float: middle; margin-bottom: 15px; margin-right:3px;"></p></li>
</ul>
</section><section id="hired-by-google" class="slide level2">
<h1>Hired by Google</h1>
<p><img src="figures/luis.jpg" style="height: 256px; float: middle; margin-bottom: 15px; margin-right: 3px;"><img src="figures/torsten.jpg" style="height: 256px; float: middle; margin-bottom: 15px; margin-right:3px;"><img src="figures/gang.jpg" style="height: 256px; float: middle; margin-bottom: 15px; margin-right:3px;"></p>
</section></section>
<section><section id="optimal-templates" class="titleslide slide level1"><h1>Optimal Templates</h1></section><section id="optimal-templates-1" class="slide level2">
<h1>“Optimal” templates (?)</h1>
<ul>
<li class="fragment"><p>unbiased wrt measurement space</p></li>
<li class="fragment"><p>space is non-linear: reference matters</p></li>
<li class="fragment"><p>encodes prior information: still just averages (usually)</p></li>
<li class="fragment"><p>concept extends across modalities, anatomy, temporality, etc</p></li>
</ul>
</section><section id="faces-brains-whatever" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.060.jpg" /></p>
</section><section id="faces-brains-whatever-1" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.061.jpg" /></p>
</section><section id="faces-brains-whatever-2" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.062.jpg" /></p>
</section><section id="faces-brains-whatever-3" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.063.jpg" /></p>
</section><section id="faces-brains-whatever-4" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.064.jpg" /></p>
</section><section id="faces-brains-whatever-5" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.065.jpg" /></p>
</section><section id="faces-brains-whatever-6" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.066.jpg" /></p>
</section><section id="faces-brains-whatever-7" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.067.jpg" /></p>
</section><section id="faces-brains-whatever-8" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.068.jpg" /></p>
</section><section id="faces-brains-whatever-9" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.069.jpg" /></p>
</section><section id="faces-brains-whatever-10" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.070.jpg" /></p>
</section><section id="faces-brains-whatever-11" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.071.jpg" /></p>
</section><section id="faces-brains-whatever-12" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.072.jpg" /></p>
</section><section id="faces-brains-whatever-13" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.073.jpg" /></p>
</section><section id="faces-brains-whatever-14" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.074.jpg" /></p>
</section><section id="faces-brains-whatever-15" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.075.jpg" /></p>
</section><section id="faces-brains-whatever-16" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.076.jpg" /></p>
<p>see <a href="stnava.github.io/ANTs">ANTs site</a> and <a href="stnava.github.io/ANTsDoc">ANTs Documentation page</a></p>
</section><section id="templates-from-ants-colleagues-not-us" class="slide level2">
<h1>Templates from ANTs Colleagues ( not us )</h1>
<p><img src="templates/figures/templates_ants_colleagues.png" /></p>
</section><section id="templates-unlock-modalities" class="slide level2">
<h1>Templates unlock modalities</h1>
<p><img src="figures/ptbp2.png" /></p>
</section></section>
<section><section id="evaluation" class="titleslide slide level1"><h1>Evaluation</h1></section><section id="section-2" class="slide level2">
<h1></h1>
<div align="center">
<img width="3500" src="evaluation/figures/evalhistory.png" frameborder="0"></img>
</div>
</section></section>
<section><section id="ants-versus-freesurfer-quantifying-life-span-brain-health" class="titleslide slide level1"><h1>ANTs versus Freesurfer:<br /> Quantifying <em>life span</em> brain health</h1></section><section id="big-data-problem-from-public-resources" class="slide level2">
<h1>“Big data” problem from public resources</h1>
<p><img src="figures/lifebrains.jpg" /></p>
<p>TOT, NKI, IXI, Oasis, ADNI … several thousand images</p>
</section><section id="ants-versus-freesurfer-quantifying-life-span-brain-health-1" class="slide level2">
<h1>ANTs versus Freesurfer:<br /> Quantifying <em>life span</em> brain health</h1>
<ul>
<li class="fragment"><p>Freesurfer is the historical standard for measuring cortical thickness</p></li>
<li class="fragment"><p>instead of using surfaces to measure cortical thickness, we use the image space <em>DiReCTly</em></p></li>
<li class="fragment"><p><a href="http://stnava.github.io/ANTsTalk/#/putting-it-all-together-can-we-quantify-life-span-brain-health-in-individuals-and-in-populations">see this section of a different talk</a></p></li>
<li class="fragment"><p>and this “big data” paper: <a href="http://www.ncbi.nlm.nih.gov/pubmed/24879923">Large-scale evaluation of ANTs and FreeSurfer cortical thickness measurements</a></p></li>
<li class="fragment"><p>comparison of prediction from automated cortical thickness measurement from 4 public datasets</p></li>
<li class="fragment"><p><span class="math">\(&gt;\)</span> 1200 subjects, age 7 to over 90 years old</p></li>
<li class="fragment"><p><em>hint</em>: ANTs thickness measurements have higher prediction accuracy relative to Freesurfer ( implying we extract more information from the data )</p></li>
<li class="fragment"><p>ANTs methods consistently improve statistical power <a href="http://www.ncbi.nlm.nih.gov/pubmed/24687814">eigenanatomy</a>, <a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=syn+epstein+avants">syn</a>, <a href="http://www.ncbi.nlm.nih.gov/pubmed/24817849">itkv4</a> … also, see <a href="http://www.ncbi.nlm.nih.gov/pubmed/24650605">Schwarz CG, et al.</a> re: TBSS and related work in fMRI <a href="http://www.ncbi.nlm.nih.gov/pubmed/15980148">Miller, PNAS</a>, <a href="http://www.ncbi.nlm.nih.gov/pubmed/24167043">Azab, et al in Hippocampus</a>.</p></li>
</ul>
</section><section id="cortical-thickness-estimation" class="slide level2">
<h1>Cortical thickness estimation</h1>
<div align="center">
<img height="250" src="./figures/corticalThicknessEstimation.png" frameborder="0"></img>
</div>
<p>In contrast to FreeSurfer which warps coupled surface meshes to segment the gray matter, <em>ANTs</em> diffeomorphically registers the white matter to the combined gray/white matters while simultaneously estimating thickness.</p>
</section></section>
<section><section id="new-work" class="titleslide slide level1"><h1>New work</h1></section><section id="rkrns" class="slide level2">
<h1>RKRNS</h1>
<p><a href="stnava.github.io/RKRNS">link</a></p>
<p>What mathematical encoding of language reflects both brain activity and “our” understanding of semantics?</p>
</section><section id="ripmarc-imputation-strutural-networks-etc." class="slide level2">
<h1>RIPMARC: Imputation, strutural networks, etc.</h1>
<p><img src="figures/ripmmarc_inter.png" /></p>
<p>MICCAI 2014, Neuroimage 2015</p>
</section><section id="big-image-registration" class="slide level2">
<h1>Big image registration</h1>
</section></section>
<section><section id="longitudinal-processing-with-ants" class="titleslide slide level1"><h1>Longitudinal processing with ANTs</h1></section><section id="ants-longitudinal-pipeline" class="slide level2">
<h1>ANTs longitudinal pipeline</h1>
<p><img src="longitudinal/figures/longpipe.png" /></p>
<p>see <a href="http://link.springer.com/chapter/10.1007/978-3-642-15705-9_40">link to paper</a></p>
<p>and <a href="http://www.ncbi.nlm.nih.gov/pubmed/20005963">unbiased analysis paper</a></p>
<p>plus <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3581852/">longitudinal recommendation paper</a></p>
</section><section id="ants-longitudinal-pipeline-1" class="slide level2">
<h1>ANTs longitudinal pipeline</h1>
<p><img src="longitudinal/figures/longpipeex.png" /></p>
</section><section id="ants-longitudinal-pipeline-2" class="slide level2">
<h1>ANTs longitudinal pipeline</h1>
<p><img src="longitudinal/figures/babystudy.png" /></p>
</section></section>
<section><section id="cortical-thickness-with-lesions" class="titleslide slide level1"><h1>Cortical thickness with lesions</h1></section><section id="antscorticalthickness.sh-is-adaptable" class="slide level2">
<h1>antsCorticalThickness.sh is adaptable!</h1>
<ol type="1">
<li class="fragment"><p>Register subject (or single subject template) to normal template.</p></li>
<li class="fragment"><p>Transform lesion mask to normal template.</p></li>
<li class="fragment"><p>Create additional “lesion” prior, i.e. <code>SmoothImage 3 ${lesionMask} 1 ${lesionPrior} 1</code>.</p></li>
<li class="fragment"><p>Subtract out lesion prior from all other priors and keep values <span class="math">\(\in [0,1]\)</span>.</p></li>
</ol>
</section><section id="modified-template-spatial-priors" class="slide level2">
<h1>Modified template spatial priors</h1>
<p><img src="lesions/figures/lesionPrior.png" /></p>
</section><section id="antscorticalthickness.sh-using-lesion-prior" class="slide level2">
<h1>antsCorticalThickness.sh using lesion prior</h1>
<p><img src="lesions/figures/lesionSegmentation.png" /></p>
<p>Only change to the command call is an additional ‘-c WM[7]’ which means “combine the 7<sup>th</sup> prior, i.e. lesion, to the white matter for cortical thickness calculation.”</p>
</section></section>
<section><section id="registration-statistics-frontiers-and-innovation" class="titleslide slide level1"><h1>Registration &amp; statistics:<br /> Frontiers and innovation</h1></section><section id="multivariate-statistical-fields-arise-from-fused-modalities" class="slide level2">
<h1>multivariate statistical fields arise from fused modalities</h1>
<p><img src="figures/statisticalfields.png" alt="images at measurement fields" /></p>
<p><em>Many opportunities for statistical advancements</em></p>
</section><section id="itkantsr-antsr" class="slide level2">
<h1>ITK+ANTs+R = <span style="color:red;"><em>ANTsR</em></span></h1>
</section><section id="agnostic-statistics" class="slide level2">
<h1>Agnostic statistics</h1>
<p><img src="figures/antsrex.jpg" /></p>
<p><a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3961542/">McMillan et al.</a></p>
</section><section id="a-quick-antsr-example" class="slide level2">
<h1>A Quick <span style="color:grey;"><em>ANTsR</em></span> example</h1>
<p>This is an executable <em>ANTsR</em> code block - <em>N</em>-dimensional statistics to go with our <em>N</em>-dimensional image processing software!</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ANTsR)
dim&lt;-<span class="dv">2</span>
filename&lt;-<span class="kw">getANTsRData</span>(<span class="st">&#39;r16&#39;</span>)
img&lt;-<span class="kw">antsImageRead</span>( filename , dim )
filename&lt;-<span class="kw">getANTsRData</span>(<span class="st">&#39;r64&#39;</span>)
img2&lt;-<span class="kw">antsImageRead</span>( filename , dim )
mask&lt;-<span class="kw">getMask</span>(img,<span class="dv">50</span>,<span class="kw">max</span>(img),T)
mask2&lt;-<span class="kw">getMask</span>(img,<span class="dv">150</span>,<span class="kw">max</span>(img),T)
nvox&lt;-<span class="kw">sum</span>( mask ==<span class="st"> </span><span class="dv">1</span> )
nvox2&lt;-<span class="kw">sum</span>( mask2 ==<span class="st"> </span><span class="dv">1</span> )</code></pre>
<p>The brain has 17395 voxels …</p>
</section><section id="a-quick-antsr-example-1" class="slide level2">
<h1>A Quick <span style="color:grey;"><em>ANTsR</em></span> example</h1>
<p>Simulate a population morphometry study - a “VBM” …</p>
<pre class="sourceCode r"><code class="sourceCode r">simnum&lt;-<span class="dv">10</span>
imglist&lt;-<span class="kw">list</span>()
imglist2&lt;-<span class="kw">list</span>()
for ( i in <span class="dv">1</span>:simnum ) {
  img1sim&lt;-<span class="kw">antsImageClone</span>(img)
  img1sim[ mask==<span class="dv">1</span> ]&lt;-<span class="kw">rnorm</span>(nvox,<span class="dt">mean=</span><span class="fl">0.5</span>)
  img1sim[ mask2==<span class="dv">1</span> ]&lt;-<span class="kw">rnorm</span>(nvox2,<span class="dt">mean=</span><span class="fl">2.0</span>)
  img2sim&lt;-<span class="kw">antsImageClone</span>(img2)
  img2sim[ mask==<span class="dv">1</span> ]&lt;-<span class="kw">rnorm</span>(nvox,<span class="dt">mean=</span><span class="fl">0.20</span>)
  imglist&lt;-<span class="kw">lappend</span>(imglist,img1sim)
  imglist2&lt;-<span class="kw">lappend</span>(imglist2,img2sim)
}
imglist&lt;-<span class="kw">lappend</span>( imglist, imglist2 )
mat&lt;-<span class="kw">imageListToMatrix</span>( imglist, mask )
DX&lt;-<span class="kw">factor</span>( <span class="kw">c</span>( <span class="kw">rep</span>(<span class="dv">0</span>,simnum), <span class="kw">rep</span>(<span class="dv">1</span>,simnum) ) )
mylmresults&lt;-<span class="kw">bigLMStats</span>( <span class="kw">lm</span>( mat ~<span class="st"> </span>DX ) )
qvals&lt;-<span class="kw">p.adjust</span>( mylmresults$pval.model ) </code></pre>
<p>The minimum q-value is 3.4727 × 10<sup>-4</sup> …</p>
</section><section id="visualize-the-histograms-of-effects" class="slide level2">
<h1>Visualize the histograms of effects</h1>
<pre class="sourceCode r"><code class="sourceCode r">whichvox&lt;-qvals &lt;<span class="st"> </span><span class="fl">1.e-2</span>
voxdf&lt;-<span class="kw">data.frame</span>( <span class="dt">volume=</span><span class="kw">c</span>( <span class="kw">as.numeric</span>( mat[,whichvox] ) ), <span class="dt">DX=</span>DX )
<span class="kw">ggplot</span>(voxdf, <span class="kw">aes</span>(volume, <span class="dt">fill =</span> DX)) +<span class="st"> </span><span class="kw">geom_density</span>(<span class="dt">alpha =</span> <span class="fl">0.2</span>)</code></pre>
<p><img src="figures/vizmorph.png" title="plot of chunk vizmorph" alt="plot of chunk vizmorph" width="864" /></p>
</section><section id="visualize-the-anatomical-distribution" class="slide level2">
<h1>Visualize the anatomical distribution</h1>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plotANTsImage</span>(img,<span class="dt">functional=</span><span class="kw">list</span>(betas),<span class="dt">threshold=</span>thresh,
  <span class="dt">outname=</span>ofn)</code></pre>
<p><img src="figures/vizmorph2.jpg" /></p>
</section><section id="network-visualization" class="slide level2">
<h1>Network visualization</h1>
<p>see <code>?plotBasicNetwork</code></p>
<p><img src="figures/network.png" /></p>
</section><section id="the-power-of-ants-r-rightarrow-reproducible-imaging-science" class="slide level2">
<h1>The power of <em>ANTs</em> <span class="math">\(+\)</span> <em>R</em> <span class="math">\(\rightarrow\)</span><br /> <span style="color:red;"><strong>Reproducible imaging science</strong></span></h1>
<p><img src="figures/antsgoals.png" /></p>
<p>… used in <a href="http://www.ncbi.nlm.nih.gov/pubmed/24096125">“Sparse canonical correlation analysis relates network-level atrophy to multivariate cognitive measures in a neurodegenerative population”</a> and several upcoming …</p>
</section></section>
<section><section id="wrap-up-conclusions" class="titleslide slide level1"><h1>Wrap-up &amp; Conclusions</h1></section><section id="questions-driving-ants-refs.1" class="slide level2">
<h1>Questions driving <em>ANTs</em> (<span class="math">\(+\)</span> Refs.1)</h1>
<ul>
<li class="fragment"><p>how should we geometrically transform anatomical coordinates?</p>
<ul>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/17659998">syn paper</a> - our geometric transformation model of choice</li>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/24409140">recent B-spline alternative/improvement</a></li>
</ul></li>
<li class="fragment"><p>how should we measure pairwise image similarity?</p>
<ul>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/20851191">similarity metric evaluation</a> compares functions for computing rigid or affine transformations between images</li>
</ul></li>
<li class="fragment"><p>what if this pair has rgb/vector/tensor voxels?</p>
<ul>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/18041273">dti similarity</a></li>
</ul></li>
<li class="fragment"><p>how do we extend from pairs to hundreds or thousands of pairs of images?</p>
<ul>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=avants+optimal+template">optimal templates</a> and <a href="http://www.ncbi.nlm.nih.gov/pubmed/24879923">spatial priors</a></li>
<li class="fragment">species specific templates/priors in <a href="http://www.ncbi.nlm.nih.gov/pubmed/23516289">chimps</a> and <a href="http://www.ncbi.nlm.nih.gov/pubmed/23284904">canines</a></li>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=tustison+freesurfer">ants “big data”</a></li>
</ul></li>
<li class="fragment"><p>how do we fuse multiple modality images at the subject and population levels?</p>
<ul>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=tustison+logical+circularity">ants auxiliary modality study</a></li>
</ul></li>
</ul>
</section><section id="questions-driving-ants-refs.2" class="slide level2">
<h1>Questions driving <em>ANTs</em> (<span class="math">\(+\)</span> Refs.2)</h1>
<ul>
<li class="fragment"><p>can diffeomorphisms <a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=tustison+freesurfer">improve cortical thickness measurement</a>?</p></li>
<li class="fragment"><p>how might we efficiently cluster the statistical fields that arise in image analysis?</p>
<ul>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=atropos+tustison">Atropos</a> segmentation and <a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=N4+tustison">N4 inhomogeneity correction</a></li>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=eigenanatomy+avants">Eigenanatomy</a> for sparse imaging-specific PCA</li>
</ul></li>
<li class="fragment"><p>how to cluster such fields when we have supervision?</p>
<ul>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=sparse+canonical+avants">sparse canonical correlation analysis for neuroimaging</a></li>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/24852460">Prior-constrained PCA</a></li>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4009425/">atlas-based label fusion</a> and <a href="http://www.ncbi.nlm.nih.gov/pubmed/21237273">MALF</a> - powerful expert systems for segmentation</li>
</ul></li>
<li class="fragment"><p>how do we implement a fully multivariate <em>interpretable</em> brain and behavior study?</p>
<ul>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=sccan+avants">SCCAN for imaging &amp; cognition</a></li>
</ul></li>
<li class="fragment"><p>how do we extend these ideas to functional MRI &amp; decoding?</p>
<ul>
<li class="fragment"><a href="http://stnava.github.io/RKRNS/">recent unpublished software</a></li>
<li class="fragment"><a href="..not%20yet...">recent work with Ben Kandel</a></li>
</ul></li>
</ul>
</section><section id="ants-longitudinal-analysis" class="slide level2">
<h1><em>ANTs</em> longitudinal analysis</h1>
<ul>
<li class="fragment">Longitudinal image processing issues
<ul>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/20005963">registration induced bias</a></li>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/23549059">general &amp; TBI-specific issues in longitudinal analysis</a></li>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/22517961">reproducibility of CBF</a></li>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/22306801">structure-specific analysis</a></li>
</ul></li>
<li class="fragment">An early study of longitudinal cortical change in ALS
<ul>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/16317254">ALS atrophy rates</a></li>
</ul></li>
<li class="fragment">Extension of standard-setting ants cortical thickness pipeline to longitudinal data
<ul>
<li class="fragment"><a href="https://github.com/stnava/DynANTs">DynANTs (unpublished)</a></li>
</ul></li>
</ul>
</section><section id="challenges-computational-and-scientific" class="slide level2">
<h1>Challenges: Computational and Scientific</h1>
<ul>
<li class="fragment">Scalability: <strong>need to fuse feature selection methods with transformation optimization</strong></li>
<li class="fragment">Scalability: <strong>need to leverage existing ITK streaming infrastructure in application level tool</strong></li>
<li class="fragment">Domain expertise: Customizable for specific problems but sometimes not specific enough</li>
<li class="fragment">Rapid development: colleagues still need familiarity with compilation for latest ANTs features</li>
<li class="fragment">Latest theoretical advances in registration not yet wrapped for users</li>
<li class="fragment">Need more <a href="http://stnava.github.io/ANTs/">Documentation</a> &amp; <a href="http://testing.psychiatry.uiowa.edu/CDash/index.php?project=ANTS">testing</a> …</li>
</ul>
</section><section id="recap" class="slide level2">
<h1>Recap</h1>
<ul>
<li class="fragment"><p>Powerful, general-purpose, <span style="color:red;">well-evaluated</span> registration and segmentation.</p></li>
<li class="fragment"><p>Differentiable maps with differentiable inverse <span style="color:red;"><span class="math">\(+\)</span> statistics in these spaces</span></p></li>
<li class="fragment"><p>Evaluated in multiple problem domains</span> via internal studies &amp; open competition</p></li>
<li class="fragment"><p>Borg philosophy: <span style="color:red;">“best of”</span> from I/O, to processing to statistical methods</p></li>
<li class="fragment"><p>Open source, testing, many examples, consistent style, multiple platforms, active community support …</p></li>
<li class="fragment"><p>Integration with <em>R</em> <span class="math">\(+\)</span> novel tools for prediction, decoding, high-to-low dimensional statistics.</p></li>
<li class="fragment"><p>Collaborations with <a href="http://neuro.debian.net/pkgs/ants.html">neurodebian</a>, <a href="http://www.slicer.org/">slicer</a>, <a href="https://github.com/BRAINSia/BRAINSTools">brainsfit</a>, <a href="http://nipy.sourceforge.net/nipype/">nipype</a>, <a href="http://www.itk.org">itk</a> and more …</p></li>
</ul>
</section><section id="tools-you-can-use-for-imaging-science" class="slide level2">
<h1>Tools you can use for imaging science</h1>
<ul>
<li class="fragment"><p>Core developers: <em>B. Avants, N. Tustison, H. J. Johnson, J. T. Duda</em></p></li>
<li class="fragment"><p>Many contributors, including users …</p></li>
<li class="fragment"><p>Multi-platform, multi-threaded C++ <a href="stnava.github.io/ANTs" class="uri">stnava.github.io/ANTs</a></p></li>
<li class="fragment"><p>Developed in conjunction with <a href="http://www.itk.org/"><a href="http://www.itk.org/" class="uri">http://www.itk.org/</a></a></p></li>
<li class="fragment"><p>R wrapping and extension <a href="stnava.github.io/ANTsR" class="uri">stnava.github.io/ANTsR</a></p></li>
<li class="fragment"><p>rapid development, regular testing <span class="math">\(+\)</span> many eyes <span class="math">\(\rightarrow\)</span> bugs are shallow</p></li>
</ul>
<p><img style="float: right" src="figures/penn.png" /> <img style="float: left" src="figures/picsl.jpg" /></p>
</section></section>
<section><section id="references" class="titleslide slide level1 unnumbered"><h1>References</h1></section></section>
    </div>
  </div>

  <script src="index_files/reveal.js-2.6.1/lib/js/head.min.js"></script>
  <script src="index_files/reveal.js-2.6.1/js/reveal.min.js"></script>

  <script>

      // Full list of configuration options available here:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        controls: true,
        progress: true,
        history: true,
        center: true,
        transition: 'fade',

        // Optional libraries used to extend on reveal.js
        dependencies: []});
    </script>

  <!-- dynamically load mathjax for compatibility with self-contained -->
  <script>
    (function () {
      var script = document.createElement("script");
      script.type = "text/javascript";
      script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
      document.getElementsByTagName("head")[0].appendChild(script);
    })();
  </script>

  </body>
</html>
