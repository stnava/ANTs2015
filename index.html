<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Brian B. Avants (PENN) and Nicholas J. Tustison (UVA)" />
  <title>Building a house withAdvanced Normalization Tools (ANTs)</title>
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <link rel="stylesheet" href="index_files/reveal.js-2.6.1/css/reveal.min.css"/>

  <!-- some tweaks to reveal css -->
  <style type="text/css">
    .reveal h1 { font-size: 2.0em; }
    .reveal h2 { font-size: 1.5em;  }
    .reveal h3 { font-size: 1.25em;	}
    .reveal h4 { font-size: 1em;	}

    .reveal .slides>section,
    .reveal .slides>section>section {
      padding: 0px 0px;
    }



    .reveal table {
      border-width: 1px;
      border-spacing: 2px;
      border-style: dotted;
      border-color: gray;
      border-collapse: collapse;
      font-size: 0.7em;
    }

    .reveal table th {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      font-weight: bold;
      border-style: dotted;
      border-color: gray;
    }

    .reveal table td {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      border-style: dotted;
      border-color: gray;
    }

  </style>

    <style type="text/css">code{white-space: pre;}</style>



<link rel="stylesheet" href="index_files/reveal.js-2.6.1/css/theme/night.css" id="theme">

<style type="text/css">
.reveal section img {
  background: rgba(255, 255, 255, 0.85);
}
</style>

    <!-- If the query includes 'print-pdf', include the PDF print sheet -->
    <script>
      if( window.location.search.match( /print-pdf/gi ) ) {
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = 'index_files/reveal.js-2.6.1/css/print/pdf.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
      }
    </script>
    <!--[if lt IE 9]>
    <script src="index_files/reveal.js-2.6.1/lib/js/html5shiv.js"></script>
    <![endif]-->

</head>
<body>
  <div class="reveal">
    <div class="slides">

<section>
    <h1 class="title"><span style="color:red;">Building a house with<br />Advanced Normalization Tools (<em>ANTs</em>)</span></h1>
    <h2 class="author">Brian B. Avants (<span style="color:blue;">PENN</span>) and <br />Nicholas J. Tustison (<span style="color:orange;">UVA</span>)</h2>
    <h3 class="date"></h3>
</section>

<section id="section" class="slide level2">
<h1></h1>
<div align="center">
<img src="figures/brian_and_edie_sedgwick.jpg" frameborder="0"></img>
</div>
<p>This talk is online at <a href="http://stnava.github.io/ANTs2015/"><a href="http://stnava.github.io/ANTs2015/" class="uri">http://stnava.github.io/ANTs2015/</a></a> with colored <a href="http://stnava.github.io/ANTs2015/">links</a> meant to be clicked for more information.</p>
</section>
<section><section id="background" class="titleslide slide level1"><h1>Background</h1></section><section id="founding-developers" class="slide level2">
<h1>Founding developers</h1>
<div align="center">
<img width="1800" src="./figures/bant2.png" frameborder="0"></img>
</div>
<p>BBA &amp; NT</p>
</section><section id="long-term-collaborators" class="slide level2">
<h1>Long-term collaborators</h1>
<p><img src="figures/antscollab.jpg" /></p>
<p><span class="math">\(+\)</span> <a href="http://neuro.debian.net/pkgs/ants.html">neurodebian</a>, <a href="http://www.slicer.org/">slicer</a>, <a href="https://github.com/BRAINSia/BRAINSTools">brainsfit</a>, <a href="http://nipy.sourceforge.net/nipype/">nipype</a>, <a href="http://www.itk.org">itk</a> and more …</p>
</section><section id="section-1" class="slide level2">
<h1></h1>
<p><img src="figures/lion.png" /></p>
<p>a pride: common way of doing things</p>
<p>… in a competitive world …</p>
</section><section id="definitions" class="slide level2">
<h1>Definitions</h1>
<ul>
<li class="fragment"><p>Registration <span class="math">\(=\)</span> estimate an “optimal” geometric mapping between image pairs or image sets (e.g. Affine)</p></li>
<li class="fragment"><p><span style="color:grey;"> Similarity <span class="math">\(=\)</span> a function relating one image to another, given a transformation (e.g. mutual information)</span></p></li>
<li class="fragment"><p>Diffeomorphisms <span class="math">\(=\)</span> differentiable map with differentiable inverse (e.g. “silly putty”, viscous fluid)</p></li>
<li class="fragment"><p><span style="color:grey;">Segmentation <span class="math">\(=\)</span> labeling tissue or anatomy in images, usually automated (e.g. K-means)</span></p></li>
<li class="fragment"><p>Multivariate <span class="math">\(=\)</span> using many voxels or measurements at once (e.g. PCA, <span class="math">\(p &gt;&gt; n\)</span> ridge regression)</span></p></li>
<li class="fragment"><p><span style="color:grey;">Multiple modality <span class="math">\(=\)</span> using many modalities at once (e.g. DTI and T1 and BOLD)</span></p></li>
<li class="fragment"><p>MALF: multi-atlas label fusion - using anatomical dictionaries to label new data</p></li>
<li class="fragment"><p><span style="color:grey;">Solutions to challenging statistical image processing problems usually need elements from each of the above</span></p></li>
</ul>
</section><section id="image-mapping-perception-1878" class="slide level2">
<h1>Image mapping &amp; perception: 1878</h1>
<p><img src="figures/galton.png" /></p>
<ul>
<li class="fragment"><p>Francis Galton: Can we see criminality in the face?</p></li>
<li class="fragment"><p>(maybe he should have used ANTs?)</p></li>
</ul>
</section><section id="initial-scope" class="slide level2">
<h1>Initial scope</h1>
<p><img src="figures/ants_initial_scope.png" /></p>
<p>… just do a better registration (tell story) …</p>
</section><section id="ants-lineage" class="slide level2">
<h1>ANTs Lineage</h1>
<p><img src="figures/lineage.jpg" /></p>
<p>References: <span class="citation" data-cites="Horn1981">Horn and Schunck (1981)</span>, <span class="citation" data-cites="Gee1993">Gee, Reivich, and Bajcsy (1993)</span>, <span class="citation" data-cites="Grenander1993">Grenander (1993)</span>, <span class="citation" data-cites="Thompson2001">Thompson et al. (2001)</span>, <span class="citation" data-cites="Miller2002">Miller, Trouve, and Younes (2002)</span>, <span class="citation" data-cites="Shen2002">Shen and Davatzikos (2002)</span>, <span class="citation" data-cites="Arnold2014">Arnold (2014)</span>, <span class="citation" data-cites="Thirion1998">Thirion (1998)</span>, <span class="citation" data-cites="Rueckert1999">Rueckert et al. (1999)</span>, <span class="citation" data-cites="Fischl2012">Fischl (2012)</span>, <span class="citation" data-cites="Ashburner2012">Ashburner (2012)</span></p>
</section><section id="diffeomorphisms" class="slide level2">
<h1>Diffeomorphisms</h1>
<div align="center">
<img width="1433" src="./figures/sillyputty.png" frameborder="0"></img>
</div>
<p>plausible physical modeling of large, invertible deformations</p>
<p>“differentiable map with differentiable inverse”</p>
</section><section id="fine-grained-and-flexible-maps" class="slide level2">
<h1>Fine-grained and flexible maps</h1>
<p><img src="figures/highresdiffeos.jpg" /></p>
<p>… to correct a misconception about diffeomorphisms …</p>
</section><section id="general-purpose-library-for-multivariate-image-registration-segmentation-statistical-analysis-tools" class="slide level2">
<h1>General purpose library for multivariate image registration, segmentation &amp; statistical analysis tools</h1>
<ul>
<li class="fragment"><p>170,000+ lines of C++, 6<span class="math">\(+\)</span> years of work, 15+ collaborators.</p></li>
<li class="fragment"><p>Generic mathematical methods that are tunable for application specific domains: no-free lunch</p></li>
<li class="fragment"><p>Deep testing on multiple platforms … osx, linux, windows.</p></li>
<li class="fragment"><p>Several “wins” in public knock-abouts ( <a href="http://www.ncbi.nlm.nih.gov/pubmed/19195496">Klein 2009</a>, <a href="http://www.ncbi.nlm.nih.gov/pubmed/21632295">Murphy 2011</a>, <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3837555/">SATA 2012 and 2013</a>, <a href="http://martinos.org/qtim/miccai2013/proc_brats_2013.pdf">BRATS 2013</a>, others )</p></li>
</ul>
<pre><code>    An algorithm must use prior knowledge about a problem 
    to do well on that problem </code></pre>
</section><section id="ants-beyond-registration" class="slide level2">
<h1>ANTs: Beyond Registration</h1>
<p><img src="figures/antscapabilities.jpg" /></p>
<p><a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=atropos+tustison">Atropos</a> segmentation, <a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=N4+tustison">N4 inhomogeneity correction</a>, <a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=eigenanatomy+avants">Eigenanatomy</a>, <a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=sparse+canonical+avants">SCCAN</a>, <a href="http://www.ncbi.nlm.nih.gov/pubmed/24852460">Prior-constrained PCA</a>, and <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4009425/">atlas-based label fusion</a> and <a href="http://www.ncbi.nlm.nih.gov/pubmed/21237273">MALF</a> (powerful expert systems for segmentation)</p>
<p>```</p>
</section><section id="on-documentation" class="slide level2">
<h1>On documentation</h1>
<p><img src="figures/handsaw.jpg" /></p>
<p>simple and nearly self-explanatory</p>
</section><section id="on-documentation-1" class="slide level2">
<h1>On documentation</h1>
<p><img src="figures/Chainsaw.jpg" /></p>
<p>documentation is important</p>
</section><section id="on-documentation-2" class="slide level2">
<h1>On documentation</h1>
<p><img src="figures/blindmen.jpg" /></p>
<p>… developers can be blind to doc deficiencies</p>
<p>while users are blind to what we provide!</p>
</section></section>
<section><section id="ants-impact" class="titleslide slide level1"><h1>ANTs Impact</h1></section><section id="ants-statistics" class="slide level2">
<h1>ANTs Statistics</h1>
<p><img src="impact/figures/antsvisitors.png" /></p>
</section><section id="ants-neuroscience" class="slide level2">
<h1>ANTs &amp; Neuroscience</h1>
<p>We need statistical image analysis <br />at several scales in modern neuroscience</p>
<ul>
<li class="fragment"><p>Macro: <em>in vivo</em> structural and functional MRI</p></li>
<li class="fragment"><p>Micro: high-resolution post-mortem MRI links with in vivo MRI</p></li>
<li class="fragment"><p>Nano: neuron reconstruction …</p></li>
<li class="fragment"><p>Solutions that are consistent across these scales have the potential to build multi-scale feature sets or templates and provide new insights into brain structure and function</p></li>
<li class="fragment"><p>E.g. Parcellation constraints based on histology, tractography, function …</p></li>
<li class="fragment"><p>Statistical definitions of anatomy/pathology?</p></li>
<li class="fragment"><p>Reinvention of these solutions within each lab … can we mitigate this?</p></li>
<li class="fragment"><p>Reduce, reuse, recycle …</p></li>
</ul>
</section><section id="financial-impact" class="slide level2">
<h1>Financial impact</h1>
<ul>
<li class="fragment"><p>The <strong>high error rate</strong> in software makes testing for quality assurance critically important.</p></li>
<li class="fragment"><p>Bugs exist <strong>Everywhere</strong>: so don’t freak out if we admit we have bugs: we’re just being honest ( and not all devs are )</p></li>
<li class="fragment"><p>Virtually every business in the United States now depends on software for development, production, distribution, and after-sales support of products and services.</p></li>
<li class="fragment"><p>A 2002 NIST study estimated the direct costs to the software supply chain due to failure to identify (<strong>successfully test for</strong>) “bugs”</p></li>
<li class="fragment"><p>We are better at this than most … <strong>not perfect</strong></p></li>
<li class="fragment"><p>The estimate of direct costs compiled from industry survey data for the U.S. economy was <strong>$60 billion per year</strong></p></li>
<li class="fragment"><p>… this estimate did not include costs to end users such as lost business (for example, the cost of shutting down the New York Mercantile Exchange in 1998 due to a software failure).</p></li>
</ul>
</section><section id="ants-saving-society" class="slide level2">
<h1>ANTs: Saving society $$$</h1>
<p>starting with neuroscience …</p>
</section></section>
<section><section id="optimal-templates" class="titleslide slide level1"><h1>Optimal Templates</h1></section><section id="optimal-templates-1" class="slide level2">
<h1>“Optimal” templates (?)</h1>
<ul>
<li class="fragment"><p>unbiased wrt measurement space</p></li>
<li class="fragment"><p>space is non-linear: reference matters</p></li>
<li class="fragment"><p>encodes prior information: still just averages (usually)</p></li>
<li class="fragment"><p>concept extends across modalities, anatomy, temporality, etc</p></li>
</ul>
</section><section id="faces-brains-whatever" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.060.jpg" /></p>
</section><section id="faces-brains-whatever-1" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.061.jpg" /></p>
</section><section id="faces-brains-whatever-2" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.062.jpg" /></p>
</section><section id="faces-brains-whatever-3" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.063.jpg" /></p>
</section><section id="faces-brains-whatever-4" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.064.jpg" /></p>
</section><section id="faces-brains-whatever-5" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.065.jpg" /></p>
</section><section id="faces-brains-whatever-6" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.066.jpg" /></p>
</section><section id="faces-brains-whatever-7" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.067.jpg" /></p>
</section><section id="faces-brains-whatever-8" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.068.jpg" /></p>
</section><section id="faces-brains-whatever-9" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.069.jpg" /></p>
</section><section id="faces-brains-whatever-10" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.070.jpg" /></p>
</section><section id="faces-brains-whatever-11" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.071.jpg" /></p>
</section><section id="faces-brains-whatever-12" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.072.jpg" /></p>
</section><section id="faces-brains-whatever-13" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.073.jpg" /></p>
</section><section id="faces-brains-whatever-14" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.074.jpg" /></p>
</section><section id="faces-brains-whatever-15" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.075.jpg" /></p>
</section><section id="faces-brains-whatever-16" class="slide level2">
<h1>Faces, brains, whatever …</h1>
<p><img src="templates/figures/WashUJan2011.076.jpg" /></p>
<p>see <a href="stnava.github.io/ANTs">ANTs site</a> and <a href="stnava.github.io/ANTsDoc">ANTs Documentation page</a></p>
</section><section id="templates-from-ants-colleagues-not-us" class="slide level2">
<h1>Templates from ANTs Colleagues ( not us )</h1>
<p><img src="templates/figures/templates_ants_colleagues.png" /></p>
</section><section id="templates-unlock-modalities" class="slide level2">
<h1>Templates unlock modalities</h1>
<p><img src="figure/ptbp2.png" /> # Evaluation</p>
</section><section id="section-2" class="slide level2">
<h1></h1>
<div align="center">
<img width="3500" src="evaluation/figures/evalhistory.png" frameborder="0"></img>
</div>
</section></section>
<section><section id="longitudinal-processing-with-ants" class="titleslide slide level1"><h1>Longitudinal processing with ANTs</h1></section><section id="ants-longitudinal-pipeline" class="slide level2">
<h1>ANTs longitudinal pipeline</h1>
<p><img src="longitudinal/figures/longpipe.png" /></p>
<p>see <a href="http://link.springer.com/chapter/10.1007/978-3-642-15705-9_40">link to paper</a></p>
<p>and <a href="http://www.ncbi.nlm.nih.gov/pubmed/20005963">unbiased analysis paper</a></p>
<p>plus <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3581852/">longitudinal recommendation paper</a></p>
</section><section id="ants-longitudinal-pipeline-1" class="slide level2">
<h1>ANTs longitudinal pipeline</h1>
<p><img src="longitudinal/figures/longpipeex.png" /></p>
</section></section>
<section><section id="cortical-thickness-with-lesions" class="titleslide slide level1"><h1>Cortical thickness with lesions</h1></section><section id="antscorticalthickness.sh-is-adaptable" class="slide level2">
<h1>antsCorticalThickness.sh is adaptable!</h1>
<ol type="1">
<li class="fragment"><p>Register subject (or single subject template) to normal template.</p></li>
<li class="fragment"><p>Transform lesion mask to normal template.</p></li>
<li class="fragment"><p>Create additional “lesion” prior, i.e. <code>SmoothImage 3 ${lesionMask} 1 ${lesionPrior} 1</code>.</p></li>
<li class="fragment"><p>Subtract out lesion prior from all other priors and keep values <span class="math">\(\in [0,1]\)</span>.</p></li>
</ol>
</section><section id="modified-template-spatial-priors" class="slide level2">
<h1>Modified template spatial priors</h1>
<p><img src="lesions/figures/lesionPrior.png" /></p>
</section><section id="antscorticalthickness.sh-using-lesion-prior" class="slide level2">
<h1>antsCorticalThickness.sh using lesion prior</h1>
<p><img src="lesions/figures/lesionSegmentation.png" /></p>
<p>Only change to the command call is an additional ‘-c WM[7]’ which means “combine the 7<sup>th</sup> prior, i.e. lesion, to the white matter for cortical thickness calculation.”</p>
</section></section>
<section><section id="wrap-up-conclusions" class="titleslide slide level1"><h1>Wrap-up &amp; Conclusions</h1></section><section id="questions-driving-ants-refs.1" class="slide level2">
<h1>Questions driving <em>ANTs</em> (<span class="math">\(+\)</span> Refs.1)</h1>
<ul>
<li class="fragment"><p>how should we geometrically transform anatomical coordinates?</p>
<ul>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/17659998">syn paper</a> - our geometric transformation model of choice</li>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/24409140">recent B-spline alternative/improvement</a></li>
</ul></li>
<li class="fragment"><p>how should we measure pairwise image similarity?</p>
<ul>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/20851191">similarity metric evaluation</a> compares functions for computing rigid or affine transformations between images</li>
</ul></li>
<li class="fragment"><p>what if this pair has rgb/vector/tensor voxels?</p>
<ul>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/18041273">dti similarity</a></li>
</ul></li>
<li class="fragment"><p>how do we extend from pairs to hundreds or thousands of pairs of images?</p>
<ul>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=avants+optimal+template">optimal templates</a> and <a href="http://www.ncbi.nlm.nih.gov/pubmed/24879923">spatial priors</a></li>
<li class="fragment">species specific templates/priors in <a href="http://www.ncbi.nlm.nih.gov/pubmed/23516289">chimps</a> and <a href="http://www.ncbi.nlm.nih.gov/pubmed/23284904">canines</a></li>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=tustison+freesurfer">ants “big data”</a></li>
</ul></li>
<li class="fragment"><p>how do we fuse multiple modality images at the subject and population levels?</p>
<ul>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=tustison+logical+circularity">ants auxiliary modality study</a></li>
</ul></li>
</ul>
</section><section id="questions-driving-ants-refs.2" class="slide level2">
<h1>Questions driving <em>ANTs</em> (<span class="math">\(+\)</span> Refs.2)</h1>
<ul>
<li class="fragment"><p>can diffeomorphisms <a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=tustison+freesurfer">improve cortical thickness measurement</a>?</p></li>
<li class="fragment"><p>how might we efficiently cluster the statistical fields that arise in image analysis?</p>
<ul>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=atropos+tustison">Atropos</a> segmentation and <a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=N4+tustison">N4 inhomogeneity correction</a></li>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=eigenanatomy+avants">Eigenanatomy</a> for sparse imaging-specific PCA</li>
</ul></li>
<li class="fragment"><p>how to cluster such fields when we have supervision?</p>
<ul>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=sparse+canonical+avants">sparse canonical correlation analysis for neuroimaging</a></li>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/24852460">Prior-constrained PCA</a></li>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4009425/">atlas-based label fusion</a> and <a href="http://www.ncbi.nlm.nih.gov/pubmed/21237273">MALF</a> - powerful expert systems for segmentation</li>
</ul></li>
<li class="fragment"><p>how do we implement a fully multivariate <em>interpretable</em> brain and behavior study?</p>
<ul>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=sccan+avants">SCCAN for imaging &amp; cognition</a></li>
</ul></li>
<li class="fragment"><p>how do we extend these ideas to functional MRI &amp; decoding?</p>
<ul>
<li class="fragment"><a href="http://stnava.github.io/RKRNS/">recent unpublished software</a></li>
<li class="fragment"><a href="..not%20yet...">recent work with Ben Kandel</a></li>
</ul></li>
</ul>
</section><section id="ants-longitudinal-analysis" class="slide level2">
<h1><em>ANTs</em> longitudinal analysis</h1>
<ul>
<li class="fragment">Longitudinal image processing issues
<ul>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/20005963">registration induced bias</a></li>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/23549059">general &amp; TBI-specific issues in longitudinal analysis</a></li>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/22517961">reproducibility of CBF</a></li>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/22306801">structure-specific analysis</a></li>
</ul></li>
<li class="fragment">An early study of longitudinal cortical change in ALS
<ul>
<li class="fragment"><a href="http://www.ncbi.nlm.nih.gov/pubmed/16317254">ALS atrophy rates</a></li>
</ul></li>
<li class="fragment">Extension of standard-setting ants cortical thickness pipeline to longitudinal data
<ul>
<li class="fragment"><a href="https://github.com/stnava/DynANTs">DynANTs (unpublished)</a></li>
</ul></li>
</ul>
</section><section id="challenges-computational-and-scientific" class="slide level2">
<h1>Challenges: Computational and Scientific</h1>
<ul>
<li class="fragment">Scalability: <strong>need to fuse feature selection methods with transformation optimization</strong></li>
<li class="fragment">Scalability: <strong>need to leverage existing ITK streaming infrastructure in application level tool</strong></li>
<li class="fragment">Domain expertise: Customizable for specific problems but sometimes not specific enough</li>
<li class="fragment">Rapid development: colleagues still need familiarity with compilation for latest ANTs features</li>
<li class="fragment">Latest theoretical advances in registration not yet wrapped for users</li>
<li class="fragment">Need more <a href="http://stnava.github.io/ANTs/">Documentation</a> &amp; <a href="http://testing.psychiatry.uiowa.edu/CDash/index.php?project=ANTS">testing</a> …</li>
</ul>
</section><section id="recap" class="slide level2">
<h1>Recap</h1>
<ul>
<li class="fragment"><p>Powerful, general-purpose, <span style="color:red;">well-evaluated</span> registration and segmentation.</p></li>
<li class="fragment"><p>Differentiable maps with differentiable inverse <span style="color:red;"><span class="math">\(+\)</span> statistics in these spaces</span></p></li>
<li class="fragment"><p>Evaluated in multiple problem domains</span> via internal studies &amp; open competition</p></li>
<li class="fragment"><p>Borg philosophy: <span style="color:red;">“best of”</span> from I/O, to processing to statistical methods</p></li>
<li class="fragment"><p>Open source, testing, many examples, consistent style, multiple platforms, active community support …</p></li>
<li class="fragment"><p>Integration with <em>R</em> <span class="math">\(+\)</span> novel tools for prediction, decoding, high-to-low dimensional statistics.</p></li>
<li class="fragment"><p>Collaborations with <a href="http://neuro.debian.net/pkgs/ants.html">neurodebian</a>, <a href="http://www.slicer.org/">slicer</a>, <a href="https://github.com/BRAINSia/BRAINSTools">brainsfit</a>, <a href="http://nipy.sourceforge.net/nipype/">nipype</a>, <a href="http://www.itk.org">itk</a> and more …</p></li>
</ul>
</section><section id="tools-you-can-use-for-imaging-science" class="slide level2">
<h1>Tools you can use for imaging science</h1>
<ul>
<li class="fragment"><p>Core developers: <em>B. Avants, N. Tustison, H. J. Johnson, J. T. Duda</em></p></li>
<li class="fragment"><p>Many contributors, including users …</p></li>
<li class="fragment"><p>Multi-platform, multi-threaded C++ <a href="stnava.github.io/ANTs" class="uri">stnava.github.io/ANTs</a></p></li>
<li class="fragment"><p>Developed in conjunction with <a href="http://www.itk.org/"><a href="http://www.itk.org/" class="uri">http://www.itk.org/</a></a></p></li>
<li class="fragment"><p>R wrapping and extension <a href="stnava.github.io/ANTsR" class="uri">stnava.github.io/ANTsR</a></p></li>
<li class="fragment"><p>rapid development, regular testing <span class="math">\(+\)</span> many eyes <span class="math">\(\rightarrow\)</span> bugs are shallow</p></li>
</ul>
<p><img style="float: right" src="figures/penn.png" /> <img style="float: left" src="figures/picsl.jpg" /></p>
</section></section>
<section><section id="references" class="titleslide slide level1 unnumbered"><h1>References</h1></section></section>
    </div>
  </div>

  <script src="index_files/reveal.js-2.6.1/lib/js/head.min.js"></script>
  <script src="index_files/reveal.js-2.6.1/js/reveal.min.js"></script>

  <script>

      // Full list of configuration options available here:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        controls: true,
        progress: true,
        history: true,
        center: true,
        transition: 'fade',

        // Optional libraries used to extend on reveal.js
        dependencies: []});
    </script>

  <!-- dynamically load mathjax for compatibility with self-contained -->
  <script>
    (function () {
      var script = document.createElement("script");
      script.type = "text/javascript";
      script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
      document.getElementsByTagName("head")[0].appendChild(script);
    })();
  </script>

  </body>
</html>
